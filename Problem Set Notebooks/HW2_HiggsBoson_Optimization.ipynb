{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5IcetVk_9yt"
   },
   "source": [
    "### Homework 2: Discover the Higgs Boson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY_eyfCI_9yw"
   },
   "source": [
    "For this question, I have provided you with a (simplified) version of the simulated Higgs boson data challenge, run by Kaggle in 2014. The files, available in the \"Data\" folder, are called \"Higgs_features.csv\" and \"Higgs_labels.csv\". The labels are 0 and 1, corresponding to \"no Higgs signal\", and \"Higgs signal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYaUX_WU_9yw"
   },
   "source": [
    "1\\. Read the data into two numpy arrays or data frames, one for features and one for labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DaNSyOh_9yx"
   },
   "source": [
    "2\\. How many instances and features are in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkjI5TfW_9yx"
   },
   "source": [
    "3\\. Plot the distribution of each feature for this data set in a histogram, in one plot. Add a legend (with labels \"Feature 1\", \"Feature 2\"...) and set the transparency of the histograms (property \"alpha\") to 0.5 for clarity. Hint: make sure you are plotting each column, not each row!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKJvSmCn_9yx"
   },
   "source": [
    "4\\. Do you see anything unusual in the distribution of any of the features? What problem could this cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7o-AIqQ_9yy"
   },
   "source": [
    "5\\. How many positive (Higgs) events does your data set contain? Based on this, is the data set balanced or unbalanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVMmZwaw_9yy"
   },
   "source": [
    "6\\. On the basis of your answer to 5, which evaluation metric (accuracy, precision, recall) would you like to pick for this data set? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGPrrr1C_9yz"
   },
   "source": [
    "7\\. Use a decision tree classifier as your model, and do five fold cross validation on your data, <b> using the scoring parameter you chose above</b>. Report the mean and standard deviation of the scores obtained for the five folds.\n",
    "\n",
    "Note: If you simply set the parameter \"cv = 5\" in the cross_val_score function, this will divide the data in five sets using the first 20%, second 20%... etc of your data, which is not great if your data are in a specific order. Make sure you use cv = StratifiedKFold(shuffle=True, n_splits=5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-E8732Z_9yz"
   },
   "source": [
    "8\\. We want to now take a look at the confusion matrix for your classifier. Generate the predicted label using the \"cross_val_predict\" function, then print the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDCopstc_9y0"
   },
   "source": [
    "9\\. Given your confusion matrix, how many true positives / true negatives / false positives / false negatives are there? Do you have more type I errors (false positives) than type II errors (false negatives)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIVY4Fn5_9y0"
   },
   "source": [
    "10\\. Let's now switch to a SVC classifier. Leaving the parameters of the classifier at their default values, run a five-fold cross validation and report the scores just like you did above for the decision tree. (Note: SVMs are slow so this might take some time, a good 5 minutes on my laptop. If it takes too long, you can reduce the number of folds to 3). Which algorithm performs better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRITwfuP_9y0"
   },
   "source": [
    "11\\. Report the confusion matrix for the SVC algorithm. Do you notice a change in the distribution of the false positives and false negatives, with respect to the decision tree algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3RYFnQM_9y1"
   },
   "source": [
    "12\\. We can now try to optimize the parameters of the SVC. Because it would otherwise take a long time, we can select the first 5% of the data set (after shuffling the data set). \n",
    "\n",
    "You can do it using the code below, but you need to change the original array names for features and targets to match yours. You will then produce the two arrays \"Xlittle, ylittle\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajnSPCFK_9y1"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "ftrs, trgt = shuffle(ftrs, trgt, random_state = 13)\n",
    "\n",
    "number_samples = ftrs.shape[0]\n",
    "\n",
    "Xlittle, ylittle = ftrs[:int(number_samples*0.05),:], trgt[:int(number_samples*0.05)]\n",
    "\n",
    "Xlittle.shape #check that everything went as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiZZgRte_9y2"
   },
   "source": [
    "13\\. Set up and run a GridSearch CV with the following parameters: \n",
    "\n",
    "parameters = {'kernel':['linear','rbf'],'C':[1, 10, 100], 'gamma':[0.01, 0.1, 0.5], 'class_weight':[{1:1},{1:3},{1:5}]}\n",
    "\n",
    "You can use the code from the particle ID with SVMs notebook, but remember to change the scoring parameter to match what you did above.\n",
    "\n",
    "Note: this might take time! Set verbose = 2 in the GridSearchCV to follow the progress, and set njobs = 4 or more to speed up the process. \n",
    "\n",
    "#### Report the scores and parameters values of the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE1Gl40x_9y3"
   },
   "source": [
    "14\\. Based on what you found, would you recommend to use a Decision Tree Classifier or a Support Vector Classifier for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCuTBCDj_9y3"
   },
   "source": [
    "Extra Credit: The object GridSearchCV (probably called clf or model in your code) that you created above has an attribute \"cv\\_results\\_\" that allows you to visualize the scores for every combination of parameters; we did it in the SVM notebook. Based on this, which parameter has the highest impact (induces the largest change) on the performance of the SVC? Do you think it might be worth optimizing it further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "jIgtP4jW_9y3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
