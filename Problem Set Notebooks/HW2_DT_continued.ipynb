{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5da99b1",
   "metadata": {},
   "source": [
    "### Homework 2: Further tests with Decision Trees\n",
    "\n",
    "In this homework question, you'll use the the expanded planet habitability data set that was introduced in Studio 3 and study how a decision tree performs using feature engineering.\n",
    "\n",
    "Before working through this notebook, look back to your answer from Homework 1, Review and Discussion Question 3. \n",
    "You'll be using your proposed feature in this programming assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll do the import statements and data loading for you this time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd #new!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #how methods are imported \n",
    "\n",
    "from sklearn import metrics #this will give us access to evaluation metrics\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#Here are some packages for visualization purposes only - this cell can be skipped if troublesome\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "from sklearn.tree import export_graphviz #you can just use this if the other lines give trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569248b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make nice-looking plots\n",
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6690f17",
   "metadata": {},
   "source": [
    "We'll use the same data set that we used in Studio 3:\n",
    "- Using stellar mass, planet period, and planet distance as our starting list of features\n",
    "- Dropping any entries with missing entries\n",
    "- Dropping any outliers using a 5 sigma threshold\n",
    "\n",
    "The code block below loads the starting data set for you and applies those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../UNC-MLPhysAstr/Data/phl_exoplanet_catalog.csv', sep = ',')\n",
    "bindf = df.drop('P_HABITABLE', axis = 1) #What are we doing here? Creating a new data frame called bindf and droppoing the old habitability tag\n",
    "bindf['P_HABITABLE'] = (np.logical_or((df.P_HABITABLE == 1) , (df.P_HABITABLE == 2))) #How about here? Creating the new habitability tag\n",
    "\n",
    "bindf['P_HABITABLE'] = bindf['P_HABITABLE'].astype(int) #And here? Re-casting this column as integer\n",
    "final_features = bindf[['S_MASS', 'P_PERIOD', 'P_DISTANCE']] \n",
    "targets = bindf.P_HABITABLE\n",
    "final_features = final_features.dropna(axis = 0) #gets rid of any instance with at least one NaN in any column\n",
    "final_features = final_features[(np.abs(stats.zscore(final_features)) < 5).all(axis=1)] \n",
    "targets = targets[final_features.index]\n",
    "final_features = final_features.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868afc61",
   "metadata": {},
   "source": [
    "### Add your new engineeered feature\n",
    "\n",
    "Using your answer to HW 1 Review and Discussion Question 3, add your new feature as a new column in the LearningSet data frame. If you wish, you can add more than 1 feature!\n",
    "Suggestions: \n",
    "- You can use Pandas methods to extract a column of values from the data frame as a Pandas series. \n",
    "- Once you have a Series, you can use the pandas.Series.to_numpy() function to get the values in that column as a numpy array.\n",
    "- Mathematical operations on numpy arrays (e.g. element-wise addition, division, exponentiation, etc.) can be done with numpy's mathematical functions: https://numpy.org/doc/stable/reference/routines.math.html \n",
    "- Once you have an array containing the value of your new feature for every instance in the data frame, you can add it as a new column using the pandas.DataFrame.insert() method. See documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html#pandas.DataFrame.insert\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your new feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627802ea",
   "metadata": {},
   "source": [
    "Check that your new feature was calculated and stored correctly by examining the values in the new column. You can do this however you prefer (e.g. pandas $\\texttt{describe}$ method, make a histogram, make a scatter plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check your new feature in some fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a38cb2",
   "metadata": {},
   "source": [
    "Using cross-validation, test the results of the feature engineering by training a Decision Tree on all of the features including the new feature you added. Think carefully about which cross-validation method you should use. Make sure to choose an appropriate evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a decision tree with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e59ef",
   "metadata": {},
   "source": [
    "How did your decision tree perform? Justify/explain your choice of evaluation metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca33e4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c88cc1",
   "metadata": {},
   "source": [
    "Did your results improve with the addition of a new feature? Why or why not? Make a learning curve to help diagnose the situation, and explain what it is showing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e000d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f621a6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed37628",
   "metadata": {},
   "source": [
    "\n",
    "Given your diagnosis, change at least 1 hyperparameter and train a new Decision Tree. \n",
    "No need to use nested cross-validation. Then repeat the steps to evaluate its performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change a hyperparameter, tran a new decision tree "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323374c2",
   "metadata": {},
   "source": [
    "Explain the hyperparameter change you made: what did you change and why do you expect it to improve the decision tree performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e213a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate new model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbca268",
   "metadata": {},
   "source": [
    "Did the hyperparameter change improve the model's performance, based on the evaluation metric you chose and the learning curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008ff93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a0f3e6",
   "metadata": {},
   "source": [
    "### Acknowledgement Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a223564",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
