{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz-P3qDrmTXS"
   },
   "source": [
    "### This is a simple notebook to build and visualize the kNN algorithm.\n",
    "\n",
    "It accompanies Chapter 2 of the book.\n",
    "\n",
    "Copyright: Viviana Acquaviva (2023)\n",
    "\n",
    "Additions and Modifications by Julieta Gruszko (2025)\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
    "\n",
    "#### List the names your group members below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHBpV2eMmTXU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # how methods are imported \n",
    "\n",
    "from sklearn import metrics # this will give us access to evaluation metrics\n",
    "\n",
    "from sklearn import neighbors # here comes the method of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaBOXOvkmTXV"
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOxhdSFPmTXW"
   },
   "source": [
    "### Read in data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3TmvvCJmTXW"
   },
   "outputs": [],
   "source": [
    "LearningSet = pd.read_csv('../Data/HPLearningSet.csv')\n",
    "\n",
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) #We want to drop the first column of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt8ixgEJmTXX",
    "outputId": "2df9a696-5627-449e-ae71-4857eb2ff687"
   },
   "outputs": [],
   "source": [
    "#By now we know data frames\n",
    "\n",
    "LearningSet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJPTy62umTXX"
   },
   "source": [
    "### Let's pick the same initial train/test set we had in the previous exercise, and split into the same features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYSZgbXQmTXY"
   },
   "outputs": [],
   "source": [
    "TrainSet =  LearningSet.iloc[:13,:] #.iloc is used to slice data frames using positional indices\n",
    "\n",
    "TestSet = LearningSet.iloc[13:,:]\n",
    "\n",
    "Xtrain = TrainSet.drop(['P_NAME','P_HABITABLE'],axis=1) #This contains stellar mass, period, and distance\n",
    "\n",
    "Xtest = TestSet.drop(['P_NAME','P_HABITABLE'],axis=1)  #This contains stellar mass, period, and distance\n",
    "\n",
    "ytrain = TrainSet.P_HABITABLE #This contains the ground truth label, or output\n",
    "\n",
    "ytest = TestSet.P_HABITABLE #This contains the ground truth  label, or output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqe9XbHkmTXa"
   },
   "source": [
    "### We are now ready to deploy the kNN (k Nearest Neighbor) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaI-UEHlmTXb"
   },
   "source": [
    "k Nearest Neighbors is a simple algorithm based on the idea of distance: we look for the k (an integer) objects that are closest to the one we would like to classify, and take the majority vote among the k classes of the k neighbors.\n",
    "\n",
    "If you are wondering: what is even there to fit?\n",
    "\n",
    "As we discussed in class, finding nearest neighbors can be computationally slow, especially for large data sets. \n",
    "When it comes to kNN, sk-learn uses the \"fit\" method to organize the training data into a structure that will make it easier to find nearest neighbors for future data points you want to predict labels for. That means that while $\\texttt{fit}$ may take some time to run (especially for large data sets), subsequent calls to $\\texttt{predict}$ will be faster. This matches our usual expectations for machine learning methods: training can be slow, but you don't need to train your network many times; using a trained network to make predictions is fast, and we often call that method repeatedly. \n",
    "\n",
    "You can find more information in [this post](https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier) and in the scikit-learn documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll make our network object. We'll set the \"k\" to 3 this time, since we're working with such a small data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jHRgc_NmTXb"
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7G_QCrZmTXb",
    "outputId": "968371ff-3426-4c12-ee85-bffe547515bd"
   },
   "outputs": [],
   "source": [
    "model #Look at the model object to see hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you're not using VS Code (or you want to print the information to an output file, for example), you can get the parameters and settings in a dictionary by using:\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCtVQrn0mTXb"
   },
   "source": [
    "### For visualization purposes, let's use only the first two features to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain2D = Xtrain.iloc[# your code here. Use the same training set we started with, but select only the first 2 columns\n",
    "\n",
    "Xtest2D = Xtest.iloc[# Same for the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNWV3ylemTXc"
   },
   "source": [
    "#### Build model by applying the \".fit\" method to the training set. Then predict labels for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to fit your kNN model to the training data set\n",
    "ytestpred = # Write code to predict labels for your test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-v6dbZamTXc",
    "outputId": "f2c4d82a-d139-48d2-a483-bee3072d2245"
   },
   "outputs": [],
   "source": [
    "ytestpred, ytest.values #compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjz3_gKDmTXd"
   },
   "source": [
    "#### Calculate accuracy on the train set and on the test set (train score and test score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dS0qLYezmTXd",
    "outputId": "9d93259b-7009-4d4e-e31e-9392ad2b8b75"
   },
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(ytrain, model.predict(Xtrain2D))) #This compares the true labels for the train set with the predicted labels for the train set\n",
    "\n",
    "print() # do the same for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYgsrB-hmTXd"
   },
   "source": [
    "#### After fitting and predicting, we can access the k neighbors for each element in the test set like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dkFzNOxmTXd",
    "outputId": "e1673fa3-c57b-4b52-c93b-f8bced714ee2"
   },
   "outputs": [],
   "source": [
    "model.kneighbors(Xtest2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the documentation for the kneighbors method called above. What are these returned values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVr8eHyMmTXe"
   },
   "source": [
    "### Let's now visualize our results, similarly to what we did for the DT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just look at the data in the 2 axes we're using for the kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "a = plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker = '*',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, label = 'Train', cmap=cmap, alpha=0.5) \n",
    "\n",
    "\n",
    "a = plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker = 'o',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, label = 'Test', cmap=cmap, alpha = 0.5)\n",
    "\n",
    "# Manually create a custom legend entry\n",
    "trainmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='*', linestyle='')\n",
    "testmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='o', linestyle='')\n",
    "# Add the custom legend\n",
    "plt.legend([trainmarker, testmarker], ['Train', 'Test'])\n",
    "\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZckHuh5mTXe"
   },
   "source": [
    "We can use the distance of the third neighbor as the radius of the circle that encompasses neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQMifEZcmTXe",
    "outputId": "d1b1990d-16a5-484a-f88a-49e7a24da8d5"
   },
   "outputs": [],
   "source": [
    "for i in range(len(TestSet)): # cycle through elements of the test set\n",
    "    \n",
    "    print(model.kneighbors(Xtest2D)[0][i,2]) # this prints out the third element of the distances vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfUhn5CEnZVC"
   },
   "source": [
    "The following code draws a circle encompassing the 3 nearest neighbors for each data point. It also sets the plot range to make the circles appear circular (1 to 1 aspect ratio) and make them easier to see. Notice that the plot isn't showing us the outlier with period > 1000 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12r4kH3WmTXe",
    "outputId": "bcb48825-c119-466f-a34c-2188c429b904"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "a = plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker = '*',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, label = 'Train', cmap=cmap, alpha=0.5) \n",
    "\n",
    "\n",
    "a = plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker = 'o',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, label = 'Test', cmap=cmap, alpha = 0.5) \n",
    "\n",
    "\n",
    "for i in range(len(TestSet)): #plot neighbors\n",
    "\n",
    "    circle1=plt.Circle((TestSet['S_MASS'].iloc[i],TestSet['P_PERIOD'].iloc[i]),model.kneighbors(Xtest.iloc[:,:2])[0][i,2],\\\n",
    "                      lw = 0.7, edgecolor='k',facecolor='none')\n",
    "    \n",
    "     \n",
    "    plt.gca().add_artist(circle1)\n",
    "    \n",
    "\n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "\n",
    "# Manually create a custom legend entry\n",
    "trainmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='*', linestyle='', label='Train')\n",
    "testmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='o', linestyle='', label='Test')\n",
    "# Add the custom legend\n",
    "plt.legend([trainmarker, testmarker], ['Train', 'Test'])\n",
    "\n",
    "\n",
    "plt.legend(handles=[trainmarker,testmarker, magentapatch, bluepatch] ,\\\n",
    "           loc = 'upper left', fontsize = 14)\n",
    "\n",
    "plt.xlim(-130,70)\n",
    "plt.ylim(0,140)\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#plt.savefig('HabPlanetsKNN2features.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwfvqaHxmTXf"
   },
   "source": [
    "### Do you notice any issue here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdBW2zgTmTXf"
   },
   "source": [
    "### If one dimension has a much bigger range than others, it will dominate the decision process. This issue can be solved by <b>scaling</b>. Scaling is a very important pre-processing step for most ML algorithms.\n",
    "\n",
    "See some examples of different scaling algorithms [here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html).\n",
    "\n",
    "We will go with RobustScaler, which is more resistant to outliers than the standard version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98kHG4jKmTXf"
   },
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_z6y9A66mTXf",
    "outputId": "6a4cbae3-8885-4cbd-f104-fd43003ca377"
   },
   "outputs": [],
   "source": [
    "scaler.fit(Xtrain) # important: we don't look at the test set when we're determining the settings for the scaler, just the the train set. Then we'll apply this same scaling to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl4FXYCFmTXg"
   },
   "outputs": [],
   "source": [
    "scaledXtrain = scaler.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpL4gFD-mTXg",
    "outputId": "eb8e1f54-befa-4ae2-c725-b56bc535b0ce"
   },
   "outputs": [],
   "source": [
    "scaledXtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHI3Z4H0mTXg"
   },
   "outputs": [],
   "source": [
    "scaledXtest = scaler.transform(Xtest) # Now we apply the same scaling to the test data. note that these are now numpy arrays, not data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick review of working with numpy arrays: we can select the value in one of the columns for all the rows like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledXtrain[:, 0] # selects all rows, just column 0 (stellar mass)\n",
    "scaledXtrain[:, :2] # selects all rows, just columns 0 and 1 (stellar mass and orbital period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the orbital period and stellar mass of the scaled data. No need to color-code by habitability, we just want to see what the distributions look like after scaling.\n",
    "\n",
    "The plotting code here looks a big different, since we're working with numpy arrays and not data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "a = plt.scatter(scaledXtrain[:, 0], scaledXtrain[:, 1], marker = '*', s = 100, label = 'Train', alpha=0.5) \n",
    "\n",
    "a = plt.scatter(scaledXtest[:, 0], scaledXtest[:, 1], marker = 'o', s = 100, label = 'Test', alpha = 0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the effect of the scaling? Make sure to address the mean/median, width of the distributions, and any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCVhyjjgmTXg"
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform #This unscales if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Train your kNN model with the scaled stellar mass and scaled orbital period. Then make a prediction for the scaled test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to train and predict here. Make sure you're using the same 2 features as before, not all 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can look at the resulting neighbors for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1H7A3uhmTXh"
   },
   "outputs": [],
   "source": [
    "model.kneighbors(scaledXtest[:,:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aFNhXGinsJK"
   },
   "source": [
    " ### The distances of neighbors look more balanced and give equal weight to all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlhzo3cemTXh",
    "outputId": "4be5216b-7391-4d8c-d02e-9eb3b61a7f70"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))#, aspect_ratio = 'equal')\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "plt.scatter(scaledXTrain[:,0], scaledXTrain[:,1], marker = '*',\\\n",
    "            c = ytrain, s = 100, label = 'Train', cmap=cmap, alpha=0.5) #, \n",
    "\n",
    "plt.scatter(scaledXtest[:,0], scaledXtest[:,1], marker = 'o',\\\n",
    "            c = ytest, s = 100, label = 'Test', cmap=cmap, alpha=0.5) #label = ,\n",
    "\n",
    "for i in range(len(TestSet)):\n",
    "\n",
    "    circle1=plt.Circle((scaledXtest[i,0],scaledXtest[i,1]),model.kneighbors(scaledXtest[:,:2])[0][i,2],\\\n",
    "                       edgecolor='k',facecolor='none', lw = 0.7)\n",
    "    plt.gca().add_artist(circle1)\n",
    "\n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "# Manually create a custom legend entry\n",
    "trainmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='*', linestyle='', label='Train')\n",
    "testmarker = plt.Line2D([0], [0], markeredgecolor='black', markerfacecolor = 'none', markersize = 10, marker='o', linestyle='', label='Test')\n",
    "# Add the custom legend\n",
    "plt.legend([trainmarker, testmarker], ['Train', 'Test'])\n",
    "\n",
    "\n",
    "plt.legend(handles=[trainmarker,testmarker, magentapatch, bluepatch] ,\\\n",
    "           loc = 'upper left', fontsize = 14)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Earth Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.ylim(-1.,2.5);\n",
    "\n",
    "#plt.savefig('HabPlanetsKNNscaled.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Cf2zRHmTXh"
   },
   "source": [
    "### Note: for the purpose of application (not visualization), we should use all three features. You'll try this on the homework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdoEKOUlmTXh"
   },
   "source": [
    "### Discussion questions:\n",
    "    \n",
    "1. We discovered that kNN needs scaling! Does DT have the same issue?\n",
    "\n",
    "2. Any thoughts on strengths/weaknesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-71listmTXh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement statement: every assignment you submit will include an acknowledgement statement crediting the resources (human or otherwise) that you relied on for your work. In this case, your group mates are all already credited, but if you used any other resources, credit them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it for kNN, for now. Upload your completed notebook to Gradescope to submit it, and then you're done for today."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
