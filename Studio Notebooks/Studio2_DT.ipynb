{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPTnQOeojLVh"
   },
   "source": [
    "### This is a simple notebook to build and visualize decision trees.\n",
    "\n",
    "It accompanies Chapter 2 of the book.\n",
    "\n",
    "Copyright: Viviana Acquaviva (2023)\n",
    "\n",
    "Additions and Modifications by Julieta Gruszko (2025)\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
    "    \n",
    "Some visualization-inspiration credits:\n",
    "\n",
    "https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "\n",
    "https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176\n",
    "\n",
    "#### List the names your group members below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1474,
     "status": "ok",
     "timestamp": 1684442020804,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "_iBUfbfejLVi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd #new!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #how methods are imported \n",
    "\n",
    "from sklearn import metrics #this will give us access to evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1684442020806,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "0SSXelcEjLVk"
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1684442034718,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "qrI4uzyEjLVk"
   },
   "outputs": [],
   "source": [
    "#Here are some packages for visualization purposes only - this cell can be skipped if troublesome\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "from sklearn.tree import export_graphviz #you can just use this if the other lines give trouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj-mt1-9jLVl"
   },
   "source": [
    "### We use a selection of data from [the Planet Habitability Lab](https://phl.upr.edu/projects/habitable-exoplanets-catalog)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vckmzMDnjLVl"
   },
   "source": [
    "### We begin by reading in the data set using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwza1eXijLVl"
   },
   "outputs": [],
   "source": [
    "LearningSet = pd.read_csv('../Data/HPLearningSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S31Snty3jLVm",
    "outputId": "1118d7eb-5abb-40ba-96d3-781ad634e08d"
   },
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6KnD1qklPyP"
   },
   "source": [
    "We want to drop the first column of the file, which is just an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoWvUe7ujLVn"
   },
   "outputs": [],
   "source": [
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO5KRUGwjLVn"
   },
   "source": [
    "The structure we created is called a data frame.\n",
    "\n",
    "It's nice because we can refer to columns with their names as well as indices, and it looks neat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sC2BBxaJjLVo",
    "outputId": "a54c383d-d477-4881-af2e-ca7f5c7e2a69"
   },
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnAqt7rPjLVo",
    "outputId": "8b05b1c3-0a2b-4bd0-9f00-63471f1f7b3d"
   },
   "outputs": [],
   "source": [
    "LearningSet[['P_NAME','S_MASS']] #One convenient way to access columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70jCyNWBjLVp",
    "outputId": "b0193954-82e7-411d-e8e1-63e153449737"
   },
   "outputs": [],
   "source": [
    "LearningSet.P_NAME #another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKO9qfkEjLVp"
   },
   "source": [
    "### Let's pick the same train/test set we had in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT6L_Pr6jLVp"
   },
   "source": [
    "In the notation below, we're using pandas' \"iloc\", which allows you to select rows or columns by index, regardless of the name of the column. The syntax of iloc is: df.iloc[row_indexer, column_indexer], where each indexer can be a single integer, a list of integers, a slice, or a boolean array. Here, we're using it to select the first 13 rows for the training set, and everything after that for hte test set. We're selecting all of the colums.\n",
    "\n",
    "We'll use this approach a lot, so make sure you're following how it works! Try making some difference selections to get comfortable with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeNobU-OlYV8"
   },
   "source": [
    "We can now creat a train and a test set. Normally this would happen at random, using the function train_test_split, but here we are following along with the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LoDG2xhjLVp"
   },
   "outputs": [],
   "source": [
    "TrainSet =  LearningSet.iloc[:13, :]  \n",
    "\n",
    "TestSet = LearningSet.iloc[13:] # This syntax also works, if you don't give column indices it will select all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DummySelection = LearningSet.iloc[YourRows, YourCols] #try some different row and column selections to get comfortable with \"iloc\". I suggest trying something other than slices\n",
    "DummySelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yCeupCejLVp",
    "outputId": "3f510a53-76bf-49fe-b3d4-79b427db98b0"
   },
   "outputs": [],
   "source": [
    "TrainSet #Take a look at the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpj_v9DRjLVq",
    "outputId": "64eab0a9-5be7-4830-f75c-b8b474e5c13b"
   },
   "outputs": [],
   "source": [
    "TestSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNx2frGmjLVq"
   },
   "source": [
    "We also need to split the train and test sets in features and labels.\n",
    "\n",
    "### Question: Which columns are the features and which are the targets/labels? Which (if any) are neither?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas gives us nice tools to remove columns from the dataframe, in addition to the methods we used above to select a single column. Use these to make data frames for the features and targets of the train and test sets.\n",
    "\n",
    "You can check the documentation for pandas \"drop\" method here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html . \n",
    "\n",
    "To select a single column, you can use the DataSet.COLUMN_NAME approach used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0rYstTjjLVq"
   },
   "outputs": [],
   "source": [
    "Xtrain = TrainSet.drop(# your code here; drop anything that isn't a feature for the train set\n",
    "\n",
    "Xtest = TestSet.drop(# same for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = # your code here to select targets for the train set\n",
    "\n",
    "ytest = # same for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to figure out our ideal splits by hand, using the features and target of the training set. It'll help us if we do some visualization of the features, so let's try plotting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet[TrainSet.P_HABITABLE == 1] #we can filter our data frame by the value of one of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TrainSet[TrainSet.P_HABITABLE == 1]) #and count the number of entries of our filtered set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the features. You could plot them in 3D, but it's more difficult to see the values in a 3D plot. Since we're looking for splits that use just 1 feature at a time, looking at a few 2D plots is easier. We'll make 3 2D scatter plots of the training data, and color-code the data points by their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0:'red', 1:'blue'}\n",
    "marker_colors = [colors[hab] for hab in TrainSet['P_HABITABLE']]\n",
    "fig, axes = plt.subplots(nrows = 3, ncols = 1, figsize=(8,10))\n",
    "\n",
    "axes[0].scatter(TrainSet['P_DISTANCE'], TrainSet['S_MASS'], c=marker_colors, alpha=0.5)\n",
    "axes[0].set_ylabel('Stellar Mass')\n",
    "axes[0].set_xlabel('Planet Distance')\n",
    "\n",
    "\n",
    "axes[1].scatter(TrainSet['P_DISTANCE'], TrainSet['P_PERIOD'], c=marker_colors, alpha=0.5)\n",
    "axes[1].set_ylabel('Orbital Period')\n",
    "axes[1].set_xlabel('Planet Distance')\n",
    "\n",
    "axes[2].scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], c=marker_colors, alpha=0.5)\n",
    "axes[2].set_ylabel('Orbital Period')\n",
    "axes[2].set_xlabel('Stellar Mass')\n",
    "# Create legend handles\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor='red', label='Not Habitable (0)'),\n",
    "    mpatches.Patch(facecolor='blue', label='Habitable (1)')\n",
    "]\n",
    "\n",
    "# Add legend to the figure (can adjust location as needed)\n",
    "axes[0].legend(handles=legend_elements, loc='lower right', title='Habitability')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By eye, it seems like a good 1st split would be at stellar mass = 0.65 solar masses. Let's calculate the change in Gini impurity for that selection. Recall that Gini impurity is:\n",
    "$$1 - \\Sigma_i f(i)^2$$\n",
    "where the summation index $i$ indicates a sum over classes and $f(i)$ is the fractional abundance of each class. The \"classes\" are the two label values we're trying to separate.\n",
    "After a split, we calculate it by summing over the impurities of two resulting nodes, with each impurity weighted by the fractional abundance of each node with respect to its parent node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that returns the Gini impurity of a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(df):\n",
    "    return #your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your new function to get the Gini impurity of the training set, prior to any splits\n",
    "gini(TrainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try applying a split and calculating the resulting change in Gini impurity. A good option seems to be at Stellar Mass $ = 0.65 M_\\odot$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitval = 0.65 #value we're splitting at\n",
    "cat = 'S_MASS' #feature we're splitting on\n",
    "\n",
    "subframe_left = TrainSet.query(f\"`{cat}` < {splitval}\") #Getting pandas to treat a string variable as a column name for filtering is a little tricky. You need to combine python's string formatting tools with pandas \"query\" function.\n",
    "subframe_right = TrainSet.query(f\"`{cat}` > {splitval}\")\n",
    "\n",
    "print(f\"Gini impurity of node with `{cat}` < {splitval} is {gini(subframe_left):.3f}\")\n",
    "print(f\"Gini impurity of node with `{cat}` > {splitval} is {gini(subframe_right):.3f}\")\n",
    "\n",
    "#Decision trees choose splits by comparing the change in gini impurity. Let's calculate the change from our split.\n",
    "delta_gini = gini(TrainSet) - (len(subframe_left)/len(TrainSet))*(gini(subframe_left))- (len(subframe_right)/len(TrainSet))*(gini(subframe_right))\n",
    "\n",
    "print(f\"Change in Gini impurity from this split is {delta_gini:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you do better? Try modifying the code above to find a better first split, as defined by the Gini impurity.\n",
    "\n",
    "You should be able to find a better split. The Gini impurity prefers to find splits that maximize the purity of one of the sets, instead of finding splits that \"balance\" the impurity among more equally-sized groups (up to a point). There are other metrics we can use for the decision tree method that lead to different split choices; you'll try these out on the homework to see how your results change. \n",
    "\n",
    "### Give the split you found (feature and value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we apply this first split, we can see where things stand and decide on a next split. Go back to the cell where you made your plots, and turn it into a function you can keep reusing with new data frames. Then study the nodes resulting from your first split to choose a second split.\n",
    "\n",
    "Once a group resulting from a split is pure (all elements have the same label), you've reached a ``leaf node\" and no further splits will improve the Gini impurity. You can ignore any pure groups in deciding on a next split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the plotting cell above and turn it into a function that takes a data frame as an input, then execute it.\n",
    "# Then use it to plot any subframes made by the first split that aren't leaf nodes yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMyData(subframe_left)\n",
    "\n",
    "#ax[1].set_ylim(4.5, 5)\n",
    "#ax[1].hlines(y=4.89, xmin=0, xmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1 more split, you should be able to make two pure nodes. Try to find what it is (you may need to zoom in on your plots to find it).\n",
    "\n",
    "To evaluate your choice, you'll need to calculate the change in Gini impurity from the previous split.  Decision tree splits are applied in sequence, so the pure node from the previous split doesn't get split any further by this second split. The Gini impurity of that node is already 0, so there's no way to improve it futher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitval =  #fill in with your choice\n",
    "cat = #fill in with your choice\n",
    "\n",
    "subframe_left_smaller = subframe_left.query(f\"`{cat}` < {splitval}\") #Getting pandas to treat a string variable as a column name is a little tricky. You need to combine python's string formatting tools with pandas \"query\" function.\n",
    "subframe_left_larger = subframe_left.query(f\"`{cat}` > {splitval}\")\n",
    "\n",
    "\n",
    "print(\"Resulting nodes:\")\n",
    "print(f\"Gini impurity of node with `{cat}` < {splitval} is {gini(subframe_left_smaller):.3f}\")\n",
    "print(f\"Gini impurity of node with `{cat}` > {splitval} is {gini(subframe_left_larger):.3f}\")\n",
    "\n",
    "\n",
    "previous_gini = (len(subframe_left)/len(TrainSet))*(gini(subframe_left))- (len(subframe_right)/len(TrainSet))*(gini(subframe_right))\n",
    "#fill in below with a calculation of the change in Gini impurity from the impurity of the previous step (given above)\n",
    "delta_gini =  previous_gini - #your expression for the current split Gini impurity\n",
    "\n",
    "print(f\"Change in Gini impurity from this split is {delta_gini:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all Gini impurities have reached 0, there's no more we can do! Further splits won't improve it any more. Let's try applying our hand-made tree to the test data, and see how we would classify it.\n",
    "\n",
    "### First, write the list of rules established by your hand-built decision tree as a series of \"if...then...\" statements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try applying your decision tree \"by hand\" to the test set and see what happens. I'll do the first node for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet[(TestSet.S_MASS > 0.83)] #should all be not habitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn:\n",
    "Fill in with a boolean selection to apply the other set of choices that should lead to a list of habitable planets, according to your decision tree. You can combine pandas selections with \"&\" for element-wise AND or \"|\" for element-wise OR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet[# your code to apply the other set of choices here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How many of the 5 test data points is our hand-built network correct for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEVQ9bmhjLVr"
   },
   "source": [
    "### We are now ready to fit the data with our decision tree!\n",
    "\n",
    "Note: The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. \n",
    "\n",
    "To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhwveIQjjLVr",
    "outputId": "afde9df5-6466-4f43-e438-60ec95bb595b"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 3) #This is how we specify which method we'd like to use, and any parameters. \n",
    "\n",
    "model.fit(Xtrain, ytrain) #This tiny line is how we build models in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cftiljCljLVr"
   },
   "source": [
    "### Finally, we can visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(40,20))  # customize according to the size of your tree\n",
    "\n",
    "tree.plot_tree(model, feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'], class_names = ['Not Habitable','Habitable'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a fancier visualization using tools called GraphViz and PyDotPlus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ewCXDmKjLVr",
    "outputId": "721bfbec-2759-4a07-faaa-357c873bb4f4"
   },
   "outputs": [],
   "source": [
    "#GraphViz creates a text description of a graph using a special \"grammar\" format called DOT language that has keywords for objects like nodes. PyDotPlus is a python tool that knows how to interpret this format and plot the results.\n",
    "dot_data = StringIO()\n",
    "#Exports our decision tree to the DOT language. We pass it our trained model, a list of the features, and a list of the classes.\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "            rounded = True)\n",
    "#Makes a graph from the DOT file we created\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "\n",
    "#To make it look nice, we can color-code the nodes by their purity. Here we're using shades of green for nodes that contain mostly not-habitable planets, and purple for those with mostly habitable planets.\n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "\n",
    "#Make the image of the graph\n",
    "graph.set_dpi('300')\n",
    "Image(graph.create_png())\n",
    "\n",
    "#Image(graph.write_png('Graph.png')) #uncomment to write out to a .png file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnQVLhEZjLVs"
   },
   "source": [
    "### We can also visualize the decisions of the classifier. The shading indicates the predicted label, while the color of the markers indicates the true labe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx1e9qh7jLVs",
    "outputId": "053eadb6-3a77-4a59-d232-59afa36a4ec9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "#Will now plot the train set and test set points\n",
    "\n",
    "plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker = '*',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Train')\n",
    "\n",
    "plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker = 'o',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Test')\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#I can add the splits to the plot\n",
    "\n",
    "plt.axvline(x=0.83, linewidth =1, ls = '-', label = '1st split', c='k')\n",
    "\n",
    "plt.axhline(y=4.891, xmin = 0, xmax = 0.655, linewidth =1, ls = '--', label = '2nd split',c='k')\n",
    "\n",
    "plt.text(0.845, 10**3, '1st split', fontsize=14)\n",
    "         \n",
    "plt.text(0.65, 6, '2nd split', fontsize=14)\n",
    "\n",
    "#Add legend, including unlabeled objects\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "predhab = mpatches.Rectangle((0,4.891),0.83,ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#FF00FF',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab1 = mpatches.Rectangle((0.83,ax.get_ylim()[0]),ax.get_xlim()[1],ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab2 = mpatches.Rectangle((0,ax.get_ylim()[0]),0.83,4.891-ax.get_ylim()[0], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legend_handles[2].set_color('k')\n",
    "leg.legend_handles[3].set_color('k')\n",
    "\n",
    "plt.gca().add_patch(predhab)\n",
    "plt.gca().add_patch(prednothab1)\n",
    "plt.gca().add_patch(prednothab2)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legend_handles[2].set_color('k')\n",
    "leg.legend_handles[3].set_color('k')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legend_handles[2],leg.legend_handles[3], magentapatch, bluepatch],\\\n",
    "           loc = 'upper left', fontsize = 14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDfagheRjLVs"
   },
   "source": [
    "### Questions: \n",
    "    \n",
    "1. What is the accuracy (percentage of correct classifications) on the training set? \n",
    "\n",
    "\n",
    "2.  How about on the test set (run the test set through the tree manually, or look at the figure above)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vNiF82JmBv5"
   },
   "source": [
    "### We want, of course, to be able to answer the questions in code as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUCUGr3bjLVs"
   },
   "outputs": [],
   "source": [
    "ypred = model.predict(Xtest) #how to generate predicted labels on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--fxWr05jLVt",
    "outputId": "4c64186e-8177-4ac8-a91d-9ff74c96ac3b"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytest, ypred) #test score -- the accuracy_score method compares the true labels with the predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the train score using code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jqvj0kNyjLVt",
    "outputId": "2593d9dc-7204-4e6d-8e1f-dda1318c65f5"
   },
   "outputs": [],
   "source": [
    "#check train score in code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy2PYSRCjLVt"
   },
   "source": [
    "### Our final exercise with the DT method will consist of picking a different train/test split.\n",
    "\n",
    "### Your turn: select the first 5 objects for an alternate test set, and all the other objects for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet2 = LearningSet.iloc[# your code here\n",
    "\n",
    "TestSet2 = LearningSet.iloc[# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVvcPXeojLVt"
   },
   "source": [
    "### Go through the motion again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain2 = #drop anything that isn't a feature from TrainSet2\n",
    "\n",
    "Xtest2 = #drop anything that isn't a feature from TestSet2\n",
    "\n",
    "ytrain2 = #select labels from TrainSet2\n",
    "\n",
    "ytest2 = #select labels from TestSet2\n",
    "\n",
    "model2 = DecisionTreeClassifier(random_state=3) # make a new DecisionTreeClassifier object\n",
    "\n",
    "# Write a line of code below to train your new model with the new training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtAEpap6jLVu"
   },
   "source": [
    "### We can now visualize the new tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSeRlNcIjLVu",
    "outputId": "aa43ad68-36c8-4fcc-e73c-6bb41f4b936a"
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model2,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "graph.set_dpi('300')\n",
    "\n",
    "Image(graph.create_png())\n",
    "\n",
    "#Image(graph.write_png('Graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckeHO9S1jLVu"
   },
   "source": [
    "### As you can see, this is quite different from the one we had before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnH3HjFujLVu"
   },
   "source": [
    "### Questions: \n",
    "    \n",
    "1. What is the accuracy (percentage of correct classifications) on the training set? \n",
    "\n",
    "\n",
    "2. How about on the test set? Don't do it by hand, it's faster to use a line of code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell to find the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avAVQvMvjLVv"
   },
   "source": [
    "### Let's consider some advantages and disadvantages of the decision tree method.\n",
    "1. What are some strengths of the Decision Tree algorithm? \n",
    "2. What are some limitations of the DT algorithm?\n",
    "3. What are some concerns we should have with this particular example of applying the DT algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding some new data points: Earth, Mars, and Venus (look up any values you don't know, NASA is a good source). Then run them though each of the two models trained above to see what they'd predict. Are our models accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-_W26J_jLVv"
   },
   "outputs": [],
   "source": [
    "# To match the structure used above, we'll make a pandas dataframe for the new data\n",
    "LocalSystemSet = pd.DataFrame({\n",
    "    'P_NAME': ['Venus', 'Earth', 'Mars' ], \n",
    "    'S_MASS': [], #fill in with correct values (units = M_solar)\n",
    "    'P_PERIOD': [], #fill in with correct values (units = days)\n",
    "    'P_DISTANCE': [], #fill in with correct values (units = AU, use the semi-major axis)\n",
    "    'P_HABITABLE': [0, 1, 1] #I'll give you the answers here, though Mars is debatable! We'll talk about adding more nuance to these categories next time\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same approach as above, drop the planet name and label columns to create a test set of local planets (your x values), and select just the label values to create a prediction target you can use to check the model accuracy (your y values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestLocal = #your code here\n",
    "\n",
    "ytestLocal = #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the \"predict\" and \"accuracy score\" methods on each of the 2 models trained above to see how they perform on our test set of local planets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do your decision tree models predict for Venus, Earth, and Mars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement statement: every assignment you submit will include an acknowledgement statement crediting the resources (human or otherwise) that you relied on for your work. In this case, your group mates are all already credited, but if you used any other resources, credit them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it for Decision Trees, for now! Upload your completed notebook to Gradescope to submit it, and move on the kNN notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
