{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJJ29EPYIZPo"
   },
   "source": [
    "### This is a simple notebook to build, visualize, and diagnose the performance of DT algorithms on the (larger) habitable planets data set.\n",
    "\n",
    "It accompanies Chapter 3 of the book.\n",
    "\n",
    "Data for this exercise come from [the Planet Habitability Lab](https://phl.upr.edu/projects/habitable-exoplanets-catalog).\n",
    "\n",
    "Copyright: Viviana Acquaviva (2023)\n",
    "\n",
    "Additions and Modifications by Julieta Gruszko (2025)\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
    "\n",
    "#### List the names your group members below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljtPFEhHIZPp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLGwHWx2IZPp"
   },
   "outputs": [],
   "source": [
    "from io import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnebtKDXIZPq"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "font = {'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "\n",
    "pd.set_option('display.max_columns', 100) #These ensure that we can visualize all rows and columns in large data frames\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sH1wbpSIZPq"
   },
   "source": [
    "### Step 1: Preliminary data analysis/exploration.\n",
    "\n",
    "Once we are working with research-level data sets, our first step should always be data exploration.\n",
    "\n",
    "We can read the data in a data frame, as we did previously, and do some preliminary data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsKv6nypIZPr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/phl_exoplanet_catalog.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUmR0spPIZPr",
    "outputId": "ef9a3945-f861-4bad-cdc7-d7cd8e2d5b01"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ovgWn_FJXNz"
   },
   "source": [
    "We can visualize the names of available features like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5OcYvYwIZPs",
    "outputId": "f4f89d83-5df4-4ae1-fb9d-1be3fcc2c22c"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR2zWC4rLW4Y"
   },
   "source": [
    "The \"describe\" property is very useful to visualize some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX-EBCj_IZPs",
    "outputId": "26127c83-5e33-43d2-eb43-4b6bfc993425"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXHCwG0DLaXg"
   },
   "source": [
    "Here is a way of showing summary statistics by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FZGuAITIZPt",
    "outputId": "91b60e47-230b-4f7c-c9fd-5fe75ba6070e"
   },
   "outputs": [],
   "source": [
    "df.groupby('P_HABITABLE').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "How many non-habitable planets are in our learning set? What about optimistically habitable planets (indicated by P_HABITABLE = 1) and reasonably expected to be habitable (P_HABITABLE = 2) planets?\n",
    "\n",
    "Is the data set balanced or imbalanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGrGskXjIZPt"
   },
   "source": [
    "### We start by lumping together Probably and Possibly Habitable planets, so we obtain a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoMxl3eyIZPu"
   },
   "outputs": [],
   "source": [
    "bindf = df.drop('P_HABITABLE', axis = 1) #What are we doing here? Creating a new data frame called bindf and droppoing the old habitability tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2x8iYzPIZPu"
   },
   "outputs": [],
   "source": [
    "bindf['P_HABITABLE'] = (np.logical_or((df.P_HABITABLE == 1) , (df.P_HABITABLE == 2))) #How about here? Creating the new habitability tag\n",
    "\n",
    "bindf['P_HABITABLE'] = bindf['P_HABITABLE'].astype(int) #And here? Re-casting this column as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_lByXbKIZPu",
    "outputId": "e0d2b71a-2c16-4c62-f94a-5226c1a9f729"
   },
   "outputs": [],
   "source": [
    "bindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwKYYttYIZPv"
   },
   "source": [
    "### There are several columns that we can use! Here is a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-bkyEcNIZPv"
   },
   "source": [
    "S_MAG - star magnitude \n",
    "\n",
    "S_DISTANCE - star distance (parsecs)\n",
    "\n",
    "S_METALLICITY - star metallicity (dex)\n",
    "\n",
    "S_MASS - star mass (solar units)\n",
    "\n",
    "S_RADIUS - star radius (solar units)\n",
    "\n",
    "S_AGE - star age (Gy)\n",
    "\n",
    "S_TEMPERATURE - star effective temperature (K)\n",
    "\n",
    "S_LOG_G - star log(g)\n",
    "\n",
    "P_DISTANCE - planet mean distance from the star (AU) \n",
    "\n",
    "P_FLUX - planet mean stellar flux (earth units)\n",
    "\n",
    "P_PERIOD - planet period (days) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQxclteBIZPv"
   },
   "source": [
    "### We will only select the three features we used in Chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mn9I6bOuIZPv"
   },
   "outputs": [],
   "source": [
    "final_features = bindf[['S_MASS', 'P_PERIOD', 'P_DISTANCE']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35iSX5nYIZPw"
   },
   "outputs": [],
   "source": [
    "targets = bindf.P_HABITABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeyEdbUcIZPw",
    "outputId": "850386b0-f027-4ca4-ae49-d1271823f3d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjcU3qxvIZPw"
   },
   "source": [
    "### There are some missing values (NaNs); we can see this in different ways, one of them is by using the \"describe\" property, which only counts the numerical values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPpUDG2aIZPw",
    "outputId": "bd905c3e-a5c7-46d8-f390-1b2427029ee6"
   },
   "outputs": [],
   "source": [
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvD0j-P3IZPx",
    "outputId": "a4f01bba-b977-45da-806b-85e45b3adbf9"
   },
   "outputs": [],
   "source": [
    "final_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EDZQk3YIZPx"
   },
   "source": [
    "### We can count missing data by column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OkK5rqIIZPx"
   },
   "outputs": [],
   "source": [
    "final_features.isnull().sum() #can also use .isna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntnDfwfPIZPx"
   },
   "source": [
    "### ...and get rid of them (Note: there are much better imputing strategies!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMBjxCOZIZPy",
    "outputId": "61bff874-0411-44f3-c795-ef1941b7ee8b"
   },
   "outputs": [],
   "source": [
    "final_features = final_features.dropna(axis = 0) #gets rid of any instance with at least one NaN in any column\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Which of the 3 columns we chose as features would you expect to be most difficult to measure? (Use the missing values of the learning set to make an educated guess.)\n",
    "- How many instances in our original learning set are missing at least one of the three selected features? In other words, how much data (and what fraction of our learning set) did we lose by choosing this imputing strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEmWMfaZIZPy"
   },
   "source": [
    "### Next step: search for outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1t_PvLE7IZPy"
   },
   "source": [
    "Method 1 - plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2B98y3c_IZPy",
    "outputId": "a65b8baa-b5d6-4cac-ee74-a1d22036326c"
   },
   "outputs": [],
   "source": [
    "plt.hist(final_features.iloc[:,0], bins = 100, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sihA09cIZPy"
   },
   "source": [
    "Non-pro tip: when you plot a distribution in a histogram, and the x-range seems unnecessarily large, it means that there are outliers! :) \n",
    "\n",
    "A good way to see them is to switch to a log scale on the y axis. Make that edit in the plotting code above.\n",
    "\n",
    "In this case, there is a remarkable outlier, as you can see by looking at the distribution ouput from plt.hist; the same happens for other features. \n",
    "\n",
    "But we could have also known from the difference between mean and median (which, in fact, is even more pronounced for orbital distance and period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_tGaIVlIZPz",
    "outputId": "c9c891cb-d933-4de6-ce91-6de9f957cecd"
   },
   "outputs": [],
   "source": [
    "final_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eej0sqxlMIm2"
   },
   "source": [
    "This eliminates objects with > 5 sigma outliers in any column; it counts the number of standard deviations away from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOtsnZ6JIZPz"
   },
   "outputs": [],
   "source": [
    "final_features = final_features[(np.abs(stats.zscore(final_features)) < 5).all(axis=1)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Why might this not be the ideal approach? Think about how outliers affect the distribution in question. What might be a better approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6V-UtfhIZPz"
   },
   "outputs": [],
   "source": [
    "targets = targets[final_features.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIuNpDeAIZPz"
   },
   "source": [
    "### Now we reset the index of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixaEWC6vIZPz"
   },
   "outputs": [],
   "source": [
    "final_features = final_features.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbU12k_AIZP0",
    "outputId": "fa046c8b-5a62-4bbe-daf1-82604a80073c"
   },
   "outputs": [],
   "source": [
    "final_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPrRwQ-7IZP0"
   },
   "source": [
    "### and do the same for the label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h2iEo8MIZP0"
   },
   "outputs": [],
   "source": [
    "targets = targets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsHH1vFUIZP0",
    "outputId": "bed8c126-27da-4318-b024-0a5875dd5c9f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plbw3ZBqIZP0"
   },
   "source": [
    "### Comparing the shapes, we can see that 9 outliers were eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slp_1kCDIZP0",
    "outputId": "8b5b5337-605d-4cfd-d7be-b7399d372872"
   },
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlX_fmzEIZP0"
   },
   "source": [
    "### Check balance of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pA2a4gyIZP0"
   },
   "outputs": [],
   "source": [
    "#Simple way: count 0/1s, get fraction of total\n",
    "np.sum(targets)/len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-CubjKkIZP1",
    "outputId": "eafc6a9d-4f1d-4d45-c426-bcbedafa7c1e"
   },
   "outputs": [],
   "source": [
    "np.bincount(targets) #this shows the distribution of the two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1DLcwK9IZP1"
   },
   "source": [
    "### This tells us that our data set is extremely imbalanced, and therefore, we need to be careful.\n",
    "\n",
    "### Questions:\n",
    "- What fraction of our learning set do the Habitable Planets make up?\n",
    "- Imagine we create a \"lazy classifier\" that classifies all the instances as non-habitable. What would the accuracy of this classifier be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36I65J4uIZP1"
   },
   "source": [
    "#### Finally, we can explore the data by class, to get a sense of how the two classes differ from one another. For this, we need to concatenate the feature/labels data frames, so we group by objects label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcXhMPi0IZP1",
    "outputId": "a648025c-7f3f-423c-f8c0-4eee52a1e9fb"
   },
   "outputs": [],
   "source": [
    "#Note: this generates a \"view\", not a new data frame\n",
    "\n",
    "pd.concat([final_features, targets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5oapCvqMbHW"
   },
   "source": [
    "### We can group objects by label and take a look at summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqbFF6gPIZP2",
    "outputId": "4224b43d-25ee-4261-b1cb-a00d01ce16a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([final_features, targets], axis=1).groupby('P_HABITABLE').describe(percentiles = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kgQEg_4IZP2"
   },
   "source": [
    "#### We can also just take a look at the first two features, using different colors for the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpCyhaMYIZP2",
    "outputId": "321da652-4e63-4682-d7a8-5b791f4c2ebb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "a = plt.scatter(final_features['S_MASS'], final_features['P_PERIOD'], marker = 'o',\\\n",
    "            c = targets, s = 10, cmap=cmap, alpha = 0.5, label = 'Test')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "\n",
    "plt.legend(handles=[magentapatch, bluepatch],\\\n",
    "           loc = 'lower right', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PjcgL69IZP2"
   },
   "source": [
    "### Questions: \n",
    "\n",
    "- Do the two classes (habitable and not habitable planets) show any population-level difference in the 3 features we selected? In other words, do we have any hope of classifying the instances using these 3 features? If they completely match, no ML algorithm will be able to successfully classify instances with only this information. \n",
    "\n",
    "- Based on this graph, would you expect DT or kNN to perform better? Why?\n",
    "    \n",
    "- What kind of performance can we expect (qualitatively, is the information sufficient?) Do you expect to have latent (hidden) variables that might affect the outcome beyond those that we have?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d-uLHZ7IZP3"
   },
   "source": [
    "### Ok, this is all for preliminary data exploration. Time to deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68cDP86cIZP3"
   },
   "source": [
    "We begin with a random train/test split, and will do cross validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YT0Fm02SIZP3"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(final_features, targets, random_state=2)\n",
    "Xtrain.shape, Xtest.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "What fraction of our learning set is being used as test data? Where is this being set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFgwgmeEIZP3"
   },
   "source": [
    "Let's pick the DT method (fixing random state) and build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k81KpmxIZP3",
    "outputId": "4c857734-6768-49b2-e1e1-25731495460c"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P48XBRQkIZP3"
   },
   "source": [
    "#### Let's visualize the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5_bktvDIZP4",
    "outputId": "54983442-c350-45e6-d1c7-fe590e951a1e"
   },
   "outputs": [],
   "source": [
    "# Reminder: The features are always randomly permuted at each split. \n",
    "# Therefore, the best found split may vary, even with the same training data \n",
    "# and max_features=n_features, if the improvement of the criterion is identical \n",
    "# for several splits enumerated during the search of the best split. \n",
    "# To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(float(ii)) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "#graph.write_png('Graph.png',dpi = 300)\n",
    "        \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dCtheafIZP4"
   },
   "source": [
    "### Question: Can you predict the accuracy score on the train set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cujOztjkIZP4"
   },
   "source": [
    "### Let's take a look at train/test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohSKLq3XIZP4",
    "outputId": "be04b130-ad80-47b7-f551-c8184c0ca68c"
   },
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(ytrain, model.predict(Xtrain))) #train score\n",
    "\n",
    "print(metrics.accuracy_score(ytest, model.predict(Xtest))) #test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ0GjH3fIZP4"
   },
   "source": [
    "This looks pretty high, but how does it compare with the accuracy of a lazy classifier that places everything in the \"not habitable\" category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvlVwXOIIZP4",
    "outputId": "430e9066-a78a-4ace-f36d-b9c5276979eb"
   },
   "outputs": [],
   "source": [
    "#Dummy classifier would return all 0's as targets\n",
    "\n",
    "print(metrics.accuracy_score(ytest, np.zeros(len(ytest)))) #performance of a dummy classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4eWmfATIZP4"
   },
   "source": [
    "### We can look at other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRZUtEsuIZP4",
    "outputId": "e55166f9-c3e6-4b6b-d40f-f52113c2d6e4"
   },
   "outputs": [],
   "source": [
    "print(metrics.precision_score(ytest,model.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxI6kXBkIZP4",
    "outputId": "e467e3a4-e592-4ecb-9cfd-ecfd3870b160"
   },
   "outputs": [],
   "source": [
    "print(metrics.recall_score(ytest,model.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKu5-1D1IZP5"
   },
   "source": [
    "How are they overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPAUKb21IZP5"
   },
   "source": [
    "Not great.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiIJRcBIIZP5"
   },
   "source": [
    "### You know what we would need in order to understand exactly how the model is working? A confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6A4kfShIZP5"
   },
   "outputs": [],
   "source": [
    "# This code just makes the plot. You have to pass it the confusion matrix and list of classes.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                 color=\"green\" if i == j else \"red\", fontsize = 30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMX1YSN-IZP5"
   },
   "source": [
    "### We can plot the confusion matrix.\n",
    "\n",
    "Note that so far, we use the predictions on *one* test fold, so the numbers will refer to the test set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKwuAJDqIZP5",
    "outputId": "49eb7149-d024-4931-c438-aae681b738d2"
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest,model.predict(Xtest))\n",
    "\n",
    "plot_confusion_matrix(cm, ['Not Hab','Hab'], cmap = plt.cm.Pastel2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYrVFJ1EIZP5"
   },
   "source": [
    "### We can now implement three flavors of k-fold Cross Validation.\n",
    "\n",
    "Note: you can fix the random seed for exactly reproducible behavior.\n",
    "\n",
    "The three methods below are:\n",
    "- Standard version, no shuffling or stratification\n",
    "- Shuffled version, without stratification\n",
    "- Shuffled and stratified version, ensures that class distributions resemble the entire data set\n",
    "\n",
    "You should avoid the first one of these! Sometimes our data sets will have instances ordered by their labels, so not shuffling can be dangerous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3tgyeq0IZP5"
   },
   "outputs": [],
   "source": [
    "# This is the standard version. Important: it doesn't shuffle the data, \n",
    "# so if your positive examples are all at the beginning or all the end, it might lead to disastrous results.\n",
    "\n",
    "cv1 = KFold(n_splits = 5)\n",
    "\n",
    "#This is v2: shuffling added (recommended!)\n",
    "\n",
    "cv2 = KFold(shuffle = True, n_splits = 5, random_state=5)\n",
    "\n",
    "# STRATIFICATION ensures that the class distributions in each split resembles those of the \n",
    "# entire data set \n",
    "\n",
    "cv3 = StratifiedKFold(shuffle = True, n_splits = 5, random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQFyNmc9IZP6"
   },
   "source": [
    "### Effect of stratification: let's look at the class count in each set of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIbpYduJIZP6",
    "outputId": "41c27d0e-98f3-450d-e7ff-c2fc3271f709"
   },
   "outputs": [],
   "source": [
    "for train, test in cv1.split(final_features, targets): #Just how they are in original data set\n",
    "...     print('train -  {}   |   test -  {}'.format(\n",
    "...         np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZg7gc7uIZP6",
    "outputId": "0d698812-1755-462a-a963-e3a45af2934a"
   },
   "outputs": [],
   "source": [
    "for train, test in cv2.split(final_features, targets): #One random selection\n",
    "...     print('train -  {}   |   test -  {}'.format(\n",
    "...         np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISO2zCatIZP6",
    "outputId": "788b6dd5-2c79-4266-e4c5-1f31ff91387f"
   },
   "outputs": [],
   "source": [
    "for train, test in cv3.split(final_features, targets): #One adjusted-for random selection\n",
    "...     print('train -  {}   |   test -  {}'.format(\n",
    "...         np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8OAjSnIZP6"
   },
   "source": [
    "### The handy function cross\\_validate provides the scores (specified by the chosen scoring parameter), in dictionary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2Fa8MSeIZP6"
   },
   "outputs": [],
   "source": [
    "scores1 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv1, scoring = 'accuracy')\n",
    "\n",
    "scores2 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv2, scoring = 'accuracy')\n",
    "\n",
    "scores3 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Tje6E2tIZP7",
    "outputId": "2a0ce54c-9cc7-4186-efa1-a860ef5ace4f"
   },
   "outputs": [],
   "source": [
    "scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36A2xvnVIZP7"
   },
   "source": [
    "#### We can now calculate an average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eewIaY4IZP7",
    "outputId": "1aad500e-492b-4824-9992-ef4048c5f419"
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}\".format(scores1['test_score'].mean()), \"{:.3f}\".format(scores1['test_score'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZ4QnrOpIZP7",
    "outputId": "80eb239b-b090-4f6d-b750-50ee5223d6ce"
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}\".format(scores2['test_score'].mean()), \"{:.3f}\".format(scores2['test_score'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Rmw2r8uIZP7",
    "outputId": "d33ba392-6734-4468-eb58-2241cf606918"
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}\".format(scores3['test_score'].mean()), \"{:.3f}\".format(scores3['test_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvYL7VvGIZP7"
   },
   "source": [
    "#### Question: are the differences statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5msg8QCIZP8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7SglIALIZP8"
   },
   "source": [
    "### Let's now use recall as our scoring parameter. Will the model that is the outcome of the training step change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3yqxGYZNHt7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJaSKgq0IZP8"
   },
   "outputs": [],
   "source": [
    "scores1 = cross_validate(DecisionTreeClassifier(random_state=1), final_features, targets, cv = cv1, scoring = 'recall')\n",
    "\n",
    "scores2 = cross_validate(DecisionTreeClassifier(random_state=1), final_features, targets, cv = cv2, scoring = 'recall')\n",
    "\n",
    "scores3 = cross_validate(DecisionTreeClassifier(random_state=1), final_features, targets, cv = cv3, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmEvO6MiIZP8",
    "outputId": "8641d5ed-cedd-498d-a5f6-6cc0add72531",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}\".format(scores1['test_score'].mean()), \"{:.3f}\".format(scores1['test_score'].std()))\n",
    "print(\"{:.3f}\".format(scores2['test_score'].mean()), \"{:.3f}\".format(scores2['test_score'].std()))\n",
    "print(\"{:.3f}\".format(scores3['test_score'].mean()), \"{:.3f}\".format(scores3['test_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tov-T3ayIZP8"
   },
   "source": [
    "### If desired, we can ask for the train scores as well. This is very helpful when diagnosing bias vs variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrdkkGB6IZP8"
   },
   "outputs": [],
   "source": [
    "scores1 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv1, scoring = 'recall', \\\n",
    "                         return_train_score = True)\n",
    "\n",
    "scores2 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv2, scoring = 'recall', \\\n",
    "                         return_train_score = True)\n",
    "\n",
    "scores3 = cross_validate(DecisionTreeClassifier(), final_features, targets, cv = cv3, scoring = 'recall', \n",
    "                         return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuX5csLUIZP8",
    "outputId": "6d514a5c-9275-4afd-a536-041cd0f17f8e"
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}\".format(scores1['test_score'].mean()), \"{:.3f}\".format(scores1['train_score'].mean()))\n",
    "print(\"{:.3f}\".format(scores2['test_score'].mean()), \"{:.3f}\".format(scores2['train_score'].mean()))\n",
    "print(\"{:.3f}\".format(scores3['test_score'].mean()), \"{:.3f}\".format(scores3['train_score'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the recall scores on the train set are perfect. Note that while we generally can't predict one metric from the other (for example, we can't generally predict what recall is if we know the accuracy), when the accuracy score is 100%, it means that the model doesn't make any mistakes, so precision and recall will also be 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLWgxZzrIZP8"
   },
   "source": [
    "### The cross\\_validate function is useful to calculate the score, but does not produce predicted labels.\n",
    "\n",
    "#### These can be obtained by using the cross\\_val\\_predict function, which saves the predictions for each of the k test folds, and compiles them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m98LhdJeIZP9"
   },
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(random_state = 3)\n",
    "\n",
    "y1 = cross_val_predict(model1, final_features, targets, cv = cv1) #these are the predictions,\n",
    "                                                                #and they are independent of the scoring parameter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMHtWfvfIZP-"
   },
   "source": [
    "This output is useful to build the \"full\" confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6O8o9GzIZP-",
    "outputId": "b3f3a7aa-ec1d-41b8-8b06-be132ba0a1fe"
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(targets,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLkoj5R3IZP_"
   },
   "source": [
    "### However, things may change if I use a different cross validation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JHnuYhtIZP_"
   },
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(random_state = 3)\n",
    "\n",
    "y1 = cross_val_predict(model1, final_features, targets, cv = cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LRPE_DRIZP_"
   },
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier(random_state = 3)\n",
    "\n",
    "y2 = cross_val_predict(model2, final_features, targets, cv = cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4tOp9CzIZP_",
    "outputId": "099cd67d-6fe5-4bfa-bb5c-08089705269d"
   },
   "outputs": [],
   "source": [
    "np.sum(y1-y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZGhHRqoIZQA"
   },
   "outputs": [],
   "source": [
    "np.sum(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGTu7wayIZQA",
    "outputId": "8a135a45-bc1f-4f72-cd11-d883eda63cd8"
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(targets,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo9TmxFrIZQA",
    "outputId": "c7834f74-e33a-4004-beb7-2b406ead98d4"
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(targets,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khMpuiMpIZQA"
   },
   "source": [
    "This is a good reminder that the confusion matrix is also only one possible realization of the model, and is subject to random fluctuations just like the cross validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvZtArZIZQA"
   },
   "source": [
    "### Finally, we can plot learning curves, using this handy function from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UCaVWQBIZQA"
   },
   "source": [
    "Learning curves are helpful in order to visualize the training scores vs the test scores, and how they vary as a function of data set size. They allow us to determine whether we have enough learning data, AND whether we have a high bias or high variance problem.\n",
    "\n",
    "The source code below is a slight modification of [this code](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xG07PI-1IZQB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=5,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), scoring = 'accuracy'):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(str(scoring))\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score from cross-validation\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utrexOA5IZQB"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Vk5lhA4IZQB",
    "outputId": "94a190dc-cc6d-4263-c63d-38c78bdb0619"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(model, 'DT (default params)', final_features, targets,  cv = cv3, scoring = 'recall');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many times was the model trained to create the plot above? In other words, how many calls to $ \\texttt{fit} $ did the  $\\texttt{plot\\_learning\\_curve} $ function make? This is an important number to know ahead of time if you're using a computationally intensive model!\n",
    "\n",
    "- What is being shown by the filled bands in the plot above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nk8BWJ7zIZQB"
   },
   "source": [
    "### Conclusions: \n",
    "- How is our DT model doing? Does it suffer from high variance or high bias? \n",
    "- What would you suggest we do to improve the model? Make at least 2 suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZaB-i7AIZQB"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6VjJojsIZQB"
   },
   "source": [
    "#### We won't look at the kNN classifier here, but we'll follow up with it on Homework 2!\n",
    "\n",
    "Chapter 3 of the book discusses additional applications, like the kNN algorithm results, and the case of a 3-class classifier.\n",
    "\n",
    "### Acknowledgement Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload your completed notebook to Gradescope to submit it, and then you're done for today."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
