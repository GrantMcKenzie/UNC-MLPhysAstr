{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vOMEueGcjKE"
   },
   "source": [
    "## Welcome to your first studio notebook! \n",
    "### This is a simple notebook to infer the parameters of a straight line model. \n",
    "\n",
    "It accompanies Chapter 1 of the book.\n",
    "We'll continue building on it as part of your first homework assignment.\n",
    "\n",
    "Copyright: Viviana Acquaviva (2023)\n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)\n",
    "\n",
    "Modified by Julieta Gruszko (2025)\n",
    "\n",
    "#### List the names your group members below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1684440003814,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "lxAagiNIcjKH"
   },
   "outputs": [],
   "source": [
    "# First, let's import the packages we'll use\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1684440003816,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "spUsZIVXcjKJ"
   },
   "outputs": [],
   "source": [
    "# Here are some settings to make the plots look nicer\n",
    "font = {'size'   : 14}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "#matplotlib.rcParams.update({'figure.autolayout': False})\n",
    "#matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaYlojxpcuU4"
   },
   "source": [
    "In this notebook, we generate some data that follow a linear relationship with some noise, and we use a grid search to find the best fit model, with and without considering the uncertainties. Then, we'll try some machine learning models on the same data.\n",
    "\n",
    "These data could represent any measurements where a linear relationship is a good model for the underlying physics. Let's imagine them as measurements taken of distance traveled at difference points in time by a cart on a track moving at constant velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1684440079713,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "6ltRVilycjKK"
   },
   "outputs": [],
   "source": [
    "np.random.seed(16) #why are we fixing the seed?\n",
    "\n",
    "x = np.arange(10) # returns a numpy array containing integers 0 to 9\n",
    "\n",
    "y = 2*x + 5 + np.random.randn(10) #generate some data with random gaussian scatter and add it to 2*x+5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two questions:\n",
    "#### 1. What is the mean and standard deviation ($\\sigma$) of the Gaussian noise being added to the y values? (Hint: VS Code should give you information about a function when you hover your mouse over it. What is randn(10) doing?)\n",
    "#### 2. If the x values are times in s and the y values are distances in m, what is the \"true\" velocity of the cart?\n",
    "\n",
    "Put your answers in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1684440080497,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "nIhWf5CXcjKK",
    "outputId": "36adae62-8236-4691-98b9-46321b8afc5a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) #\n",
    "plt.scatter(x,y, c = 'red')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('distance (m)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1684440086145,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "75InFJT2cjKM"
   },
   "outputs": [],
   "source": [
    "y = np.round(y,1) #match the book\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNtgGhEacjKM"
   },
   "source": [
    "Let's generate a grid of slopes and intercepts, after deciding a reasonable range by looking at the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1684440171516,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "LMGwE9VXcjKN"
   },
   "outputs": [],
   "source": [
    "slopes = np.linspace(1,3,101) # asks numpy to give us an array of 101 values from 1 to 3. Choosing 101 gives us nicer-looking numbers\n",
    "\n",
    "intercepts = np.linspace(4,6,101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1684440174967,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "n43R-zDkcjKO",
    "outputId": "99ed4df7-a51d-49e7-fedb-af92e8f7b6da"
   },
   "outputs": [],
   "source": [
    "slopes #just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1684440176487,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "skldmaFgcjKP",
    "outputId": "9ab7b5a2-3d62-4281-ac5b-73727c156109"
   },
   "outputs": [],
   "source": [
    "intercepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH9LLil1cjKQ"
   },
   "source": [
    "#### Note: these are already > 10000 models (curse of dimensionality!)\n",
    "\n",
    "For convenience, we can define two functions. The first implements our model (a straight line) and the second one is the sum of squared errors that we can use to evaluate each slope, intercept pair (ignoring uncertainties for now):\n",
    "$$ \\Sigma_i \\Delta y_i^2 = \\Sigma_i (y_i - \\bar{y_i})^2 = \\Sigma_i (y_i - (m x_i+b))^2 $$\n",
    "\n",
    "where the index $i$ is over the data points, $y_i$ is the distance data, and $\\bar{y_i}$ is the modeled distance at time $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1684440274441,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "5eyJ5STTcjKR"
   },
   "outputs": [],
   "source": [
    "def model(x,m,b):\n",
    "    return m*x + b\n",
    "\n",
    "def se(x,m,b,yobs):\n",
    "    return np.sum((yobs - model(x,m,b))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6wDz_sKcjKR"
   },
   "source": [
    "We can calculate the squared error for each value and save it in the \"square_errs\" array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1684440302786,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "G_LQL4WlcjKR"
   },
   "outputs": [],
   "source": [
    "square_errs = np.zeros((101,101)) #Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loops are less \"pythonic\" (and usually less efficient), but often easier to read and understand. Sometimes a nice way to work is to start by writing the loop version, and then going back and replacing those lines with more-efficient versions once you have your basic algorithm in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1684440321171,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "KEemwe5EcjKS"
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(slopes):\n",
    "    for j,b in enumerate(intercepts):\n",
    "        square_errs[i,j] = se(x,m,b,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPh55l3Xe1-I"
   },
   "source": [
    "We can also do this with a one-liner by using list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684440591987,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "BZhUKpGacjKS"
   },
   "outputs": [],
   "source": [
    "square_errs = np.array([[se(x,m,b,y) for b in intercepts] for m in slopes]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1684440343435,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "Xugo9LyGcjKT",
    "outputId": "100ae6d8-3e35-4fc2-a307-991c539584aa"
   },
   "outputs": [],
   "source": [
    "square_errs.shape #check that the array has been built properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684440343903,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "HtRBSUbucjKT",
    "outputId": "350217c8-6b5d-44f7-d11b-34f14dd32e0e"
   },
   "outputs": [],
   "source": [
    "square_errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywSsB4yWe74a"
   },
   "source": [
    "Note that this generates an array where the first index refers to slope and the second index refers to intercept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPKKultjcjKU"
   },
   "source": [
    "#### Let's figure out which model is the best fit (lowest Squared Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1684440352015,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "YCH3-HtRcjKU",
    "outputId": "78da3d28-2cfc-4fad-e7c0-402c4f8497b3"
   },
   "outputs": [],
   "source": [
    "np.argmin(square_errs) #index of min; however this corresponds to flattened array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1684440368610,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "uaQcsVFLcjKU",
    "outputId": "93a32b96-60c1-4a0c-c734-98275172478d"
   },
   "outputs": [],
   "source": [
    "indices = np.unravel_index(square_errs.argmin(), square_errs.shape) #indices of minimum value as a (row, col) pair\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypg2aTfCeI4B"
   },
   "source": [
    "We can now derive the slope and intercept for the best-fitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1684440410317,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "-X5Bm53CcjKU"
   },
   "outputs": [],
   "source": [
    "bestm, bestb = slopes[indices[0]],intercepts[indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684440410319,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "Lc9tLJVwcjKV",
    "outputId": "30e0c235-92c2-4e0b-9093-1997079e8c32"
   },
   "outputs": [],
   "source": [
    "bestm, bestb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How do the best-fit slope and y-intercept compare to the original ones?\n",
    "When you're asked something like this, it's good to make it quantitative! An easy way to do that is to give the % disagreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_8vNTpIePcn"
   },
   "source": [
    "Finally, we plot the best fit model against the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1684440429726,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "HCNJhYfRcjKV",
    "outputId": "fed6e6bc-7a87-4d4c-f366-75d0923cc68e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x,y, c = 'red') \n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('distance (m)')\n",
    "plt.plot(x, bestm * x + bestb, c = 'm'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgDvY8ozcjKW"
   },
   "source": [
    "#### What if there are varying distance measurement uncertainties on each data point? Let's see how our fit changes.\n",
    "\n",
    "First let's generate some error bars for the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1684440440338,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "HbCNm9_AcjKW"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "dy = np.random.randn(10)*np.sqrt(2) #these are the uncertainties; sign doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1684440440620,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "C3qe71c3cjKW",
    "outputId": "fa3a91e5-0a73-49f0-d0d4-f1cf0177eb6b"
   },
   "outputs": [],
   "source": [
    "dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57-WnAbTeWqy"
   },
   "source": [
    "We want to consider the uncertainties by giving more weight to data points with a lower uncertainties. This can be achieved by modifying the squared error function with an inverse weight of the uncertainties. The error function becomes the chi squared:\n",
    "\n",
    "$$\\chi^2 = \\Sigma_i \\frac{(y_i - \\bar{y_i})^2}{\\epsilon_i^2}$$\n",
    "\n",
    "where $i$ runs over all the data points, $y_i$ is the observed value, $\\bar{y_i}$ is the expected value of the model at that point, and $\\epsilon_i$ is the uncertainty of the data point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn:\n",
    "Write a function that returns the $\\chi^2$ value for an array of observed points with associated errors, given the parameters of the linear model $m$, and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(x,m,b,yobs,err):\n",
    "    return #your expression here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIO2xrwxfBwp"
   },
   "source": [
    "We can now generate the array of the modified evaluation function, and find the indices of its minimum like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1684440651262,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "Ev3vxXgWcjKX"
   },
   "outputs": [],
   "source": [
    "allchi2 = np.array([[chi2(x,m,b,y,dy) for b in intercepts] for m in slopes]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1684440651263,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "tY9SrtIZcjKX",
    "outputId": "94cfbef8-af0c-4cde-89f7-1e4a337a2093"
   },
   "outputs": [],
   "source": [
    "print(allchi2.argmin()) #index of min; however this corresponds to flattened array\n",
    "\n",
    "indices = np.unravel_index(allchi2.argmin(), allchi2.shape) #indices of minimum value as a (row, col) pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn again: as above, get the slope and y intercept of the best model and compare them to the results without uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1684440660675,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "GWYyvNJ1cjKX"
   },
   "outputs": [],
   "source": [
    "#Derive the slope and intercept for best model\n",
    "\n",
    "bestm_werr, bestb_werr = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1684440661679,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "YIdhBQvZcjKX",
    "outputId": "2831c48f-ad4f-4239-82e3-e3cd133204cf"
   },
   "outputs": [],
   "source": [
    "bestm_werr, bestb_werr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOJAMqRvfNF3"
   },
   "source": [
    "We can plot the data (with uncertainties) and the new best fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1684440707819,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "_Urw4kr9cjKZ",
    "outputId": "98d50ad4-cf92-4024-e02f-0b34a99cbf45"
   },
   "outputs": [],
   "source": [
    "plt.errorbar(x,y, np.abs(dy), marker = 'o', markersize = 3, c = 'red', linestyle = ' ')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('distance (m)')\n",
    "plt.plot(x, bestb_werr + bestm_werr * x, c = 'c');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QExhFaYAcjKZ"
   },
   "source": [
    "We can compare the two lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1684440726108,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "uLuuPVCZcjKZ",
    "outputId": "326b96e8-9ea3-419e-cc42-c437a896ab72"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.errorbar(x,y, np.abs(dy), marker = 'o', markersize = 3, c = 'red', linestyle = ' ')\n",
    "\n",
    "plt.plot(x, bestb + bestm * x, c = 'm', label = 'Fit without uncertainties')\n",
    "\n",
    "plt.plot(x, bestb_werr + bestm_werr * x, c = 'c', label = 'Fit with uncertainties')\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "\n",
    "plt.ylabel('distance (m)')\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_kKAsHxcjKa"
   },
   "source": [
    "#### Question: \n",
    "Does the change make sense? Explain what you're seeing (and why). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we'll see how using machine learning to solve this problem differs from using a \"traditional\" inference approach. \n",
    "\n",
    "We'll use the same data as before, and try two models that we'll study in depth in the coming weeks: a Decision Tree Regressor and Linear Regression. To use them, we have to first import the models from scikit-learn. We'll also use sklearn's tools to split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split our data into train/test sets with a 70/30 split. In this case, that means 3 test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10) #fix for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=3) #create train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at what points are in each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the test set is hidden: that's what we're trying to reproduce with our ML models.\n",
    "\n",
    "We'll make a model object for each of our two models, each using the default parameters from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel = DecisionTreeRegressor() # default params\n",
    "regmodel = LinearRegression() # default params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training our first model! scikit-learn's $\\texttt{fit}$ method does the training. We need to give it our training data (both the x and y values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel.fit(X_train, y_train)\n",
    "regmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, that didn't work! Luckily the error message is quite informative, and even tells us how to fix the problem. \n",
    "\n",
    "#### Your turn! Fix the error and train the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to train the decision tree model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to train the linear regression model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the print out associated with the model object returned here is quite helpful! It tells us the settings used to train the model, and you can mouse over the \"i\" to see that the model has been fitted. Clicking the \"?\" takes you to the documentation page for the model.\n",
    "\n",
    "Now, let's use our trained models to predict the y values for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = treemodel.predict(X_test)\n",
    "y_pred_reg = regmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same error as before! By now, you should be a pro at fixing it.\n",
    "### Your turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = # your code to predict tree values here\n",
    "y_pred_reg = # your code to predict regression values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test, y_pred_reg, y_pred_tree) #True/predicted by LR and DT respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the mean squared error with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_test-y_pred_reg)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_test-y_pred_tree)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, our goal in building a model is often to use it to make predictions. Let's use our two linear fits and our two ML models to predict what the cart's distance will be at t = 12 s. \n",
    "\n",
    "I'll get you started with two of the four values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linpred = bestm * 12 + bestb\n",
    "treepred = treemodel.predict(np.array(12).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: \n",
    "Find the prediction of the linear fit that takes uncertainties into account and of the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linuncpred = # your code here\n",
    "regpred = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results, including the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x,y, c = 'red', label = \"Data\")\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('distance (m)')\n",
    "plt.scatter(X_test, y_test, marker=\"x\", label=\"Test Data\", c=\"black\")\n",
    "plt.scatter(X_test, y_pred_reg, marker=\"+\", c=\"green\", label=\"Lin. Reg. Prediction\")\n",
    "plt.scatter(X_test, y_pred_tree, marker=\"+\", c=\"blue\", label=\"Tree Prediction\")\n",
    "plt.scatter(12, linpred, marker=\"*\", c=\"m\", label=\"Lin. Fit Prediction\")\n",
    "plt.scatter(12, linuncpred, marker=\"*\", c=\"c\", label=\"Lin. Fit w Unc Prediction\")\n",
    "plt.scatter(12, treepred, marker=\"+\", c=\"blue\")\n",
    "plt.scatter(12, regpred, marker=\"+\", c=\"green\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions (answer all 4 in the markdown cell below):\n",
    "1. Which of the two ML models is performing better, in this case? Back up your assessment with at least two pieces of evidence.\n",
    "\n",
    "2. What are some advantages and disadvantages of a machine learning based-approach, in the context of this problem? Hint: think about the different things we might be trying to achieve with this data - e.g. extracting the velocity and starting position of the cart, predicting future motion (extrapolation), figuring out what the cart was doing between measurements (interpolation). \n",
    "\n",
    "3. Did the ML models allow us to take the uncertainty of the measurements into account?\n",
    "\n",
    "4. We'll see in future weeks that the linear regression model we used should be equivalent to a linear fit. In this case, though, it gave us a different prediction for the point at t = 12 than either of our linear fits. Give 1 reason why that might be the case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement statement: every assignment you submit will include an acknowledgement statement crediting the resources (human or otherwise) that you relied on for your work. In this case, your group mates are all already credited, but if you used any other resources, credit them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gratefully acknowledge... (fill in if needed!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it for this studio! Upload your completed notebook to Gradescope to submit it."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PHYS448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
